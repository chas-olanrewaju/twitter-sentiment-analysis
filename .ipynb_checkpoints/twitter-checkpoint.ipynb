{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4887027d-c110-46b6-af87-2a9dbf2b50f9",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on X (Formerly Twitter): What the Public Thinks About Global Leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b0168e-6fdf-4f07-b91f-7a316d3a518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\olanr\\anaconda3\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.1.31)\n",
      "Requirement already satisfied: textblob in c:\\users\\olanr\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\olanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df818db8-712f-4d6e-977d-bd678cb29fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olanr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.1.31)\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: deep-translator\n",
      "Successfully installed deep-translator-1.11.4\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b8d5b-e613-4356-a40b-d2f70845f268",
   "metadata": {},
   "source": [
    "-https://developer.x.com/en/portal/dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eaa115c-914f-42f0-8216-f1c76fe0135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "class TwitterClient:\n",
    "    \"\"\"\n",
    "    Twitter Client using Bearer Token for sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.bearer_token = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"  # Replace with your actual token\n",
    "\n",
    "        # authenticate using Bearer Token\n",
    "        try:\n",
    "            self.client = tweepy.Client(bearer_token=self.bearer_token)\n",
    "        except Exception as e:\n",
    "            print(\"Error: Authentication Failed\", e)\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"\n",
    "        Clean tweet text by removing links, special characters, and usernames.\n",
    "        \"\"\"\n",
    "        return ' '.join(re.sub(r\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        \"\"\"\n",
    "        Translate tweet to English (if needed), clean it, and analyze sentiment.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            translated = GoogleTranslator(source='auto', target='en').translate(tweet)\n",
    "        except Exception:\n",
    "            translated = tweet  # fallback if translation fails\n",
    "    \n",
    "        cleaned = self.clean_tweet(translated)\n",
    "        analysis = TextBlob(cleaned)\n",
    "    \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, max_results):\n",
    "        \"\"\"\n",
    "        Fetch tweets using Twitter API v2 and analyze sentiment.\n",
    "        \"\"\"\n",
    "        tweets = []\n",
    "        try:\n",
    "            response = self.client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=[\"text\"])\n",
    "            if response.data is None:\n",
    "                print(\"No tweets found.\")\n",
    "                return tweets\n",
    "\n",
    "            for tweet in response.data:\n",
    "                parsed_tweet = {\n",
    "                    'text': tweet.text,\n",
    "                    'sentiment': self.get_tweet_sentiment(tweet.text)\n",
    "                }\n",
    "                tweets.append(parsed_tweet)\n",
    "\n",
    "            return tweets\n",
    "\n",
    "        except tweepy.TooManyRequests:\n",
    "            print(\"Error: Rate limit exceeded. Try again later.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error fetching tweets:\", e)\n",
    "            return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42480bd-91df-4ee9-9b2b-e5bab6035ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 10.0 %\n",
      "Negative tweets percentage: 5.0 %\n",
      "Neutral tweets percentage: 85.0 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @AfricanHub_: In a powerful address, Minister Louis Farrakhan delivered a sharp message to the West, demanding an end to føreign interfe…\n",
      "RT @BlancoGustavo10: El Presidente de Burkina Faso, Ibrahim Traoré se sacudió al imperio ladrón y está construyendo el milagro  económico d…\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "@HakeemHappyboy @Joe__Bassey The claim that Captain Ibrahim Traoré is building roads in Burkina Faso using local engineers appears true. Reports confirm a 5,000 km road project, emphasizing local resources and training, surpassing past efforts. The previous government built roads, like the 700 km MCC\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    api = TwitterClient()\n",
    "    tweets = api.get_tweets(query='Ibrahim Traoré', max_results=20)\n",
    "\n",
    "    if not tweets:\n",
    "        return\n",
    "\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    \n",
    "    print(\"Positive tweets percentage: {} %\".format(100 * len(ptweets) / len(tweets)))\n",
    "    print(\"Negative tweets percentage: {} %\".format(100 * len(ntweets) / len(tweets)))\n",
    "    print(\"Neutral tweets percentage: {} %\".format(100 * (len(tweets) - len(ptweets) - len(ntweets)) / len(tweets)))\n",
    "\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:5]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:5]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c389f69-8621-494a-a35a-4ee160f306ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 0.0 %\n",
      "Negative tweets percentage: 15.789473684210526 %\n",
      "Neutral tweets percentage: 84.21052631578948 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "RT @Imranmuhdz: \"The majority of fuel stations that were not working , they are now back to work; there is no more shortage, no more queues…\n",
      "RT @JohnFanimokun: \"We will do it (LC Coastal Road). If they don’t like the road or if it is too expensive for tolling for them, they can g…\n",
      "RT @Imranmuhdz: \"The majority of fuel stations that were not working , they are now back to work; there is no more shortage, no more queues…\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    api = TwitterClient()\n",
    "    tweets = api.get_tweets(query='Bola Ahmed Tinubu ', max_results=19)\n",
    "\n",
    "    if not tweets:\n",
    "        return\n",
    "\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*(len(tweets)-(len(ntweets)+len(ptweets)))/len(tweets)))\n",
    "\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:5]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:5]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597d207-4ca5-4b38-a6b7-7fd3d733a575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
